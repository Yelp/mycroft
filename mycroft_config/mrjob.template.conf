runners:
  emr:
    bootstrap_cmds:
      - sudo apt-get install -y python-simplejson python-pip
      - sudo pip install pip==1.5.5 --upgrade
      - sudo pip install --no-index --find-links file://$(pwd)/ -r requirements-emr.txt
      - cp oddjob-*-standalone.jar /home/hadoop/
    bootstrap_files:
      - $MYCROFTCODE/requirements-emr.txt
      - $MYCROFTCODE/aws/python-modules/*.tar.gz
      - $MYCROFTCODE/aws/python-modules/*.zip
      - $MYCROFTCODE/oddjob-*-standalone.jar
    ami_version: 2.4.9
    aws_access_key_id: ACCESS_KEY_ID
    aws_region: us-west-2
    aws_secret_access_key: SECRET_ACCESS_KEY
    base_tmp_dir: /scratch/$USER
    bootstrap_actions:
      - s3://elasticmapreduce/bootstrap-actions/configure-hadoop -m mapreduce.job.counters.limit=2000 -m mapred.reduce.tasks.speculative.execution=false -m mapred.map.tasks.speculative.execution=false
    cleanup: NONE
    cmdenv: &cmdenv
      TZ: America/Los_Angeles
      MYCROFTCODE: src-tree.tar.gz
      YELPCODE: src-tree.tar.gz
      mapreduce_job_cache_local_archives: src-tree.tar.gz
    ec2_core_instance_type: m3.xlarge
    num_ec2_core_instances: 2
    ec2_key_pair: MycroftEMRKeyPair
    ec2_key_pair_file: /mycroft_config/MycroftEMRKeyPair.pem
    emr_api_params:
      ServiceRole: EMR_DefaultRole
    emr_job_flow_pool_name: mycroft
    hadoop_extra_args:
      - -libjars
      - /home/hadoop/oddjob-1.0.1-standalone.jar
    iam_job_flow_role: EMR_EC2_DefaultRole
    jobconf:
      mapred.output.compress: "true"
      mapred.output.compression.codec: org.apache.hadoop.io.compress.GzipCodec
    max_hours_idle: 2
    pool_emr_job_flows: True
    python_archives: &python_archives
      - $MYCROFTCODE/aws/src-tree.tar.gz
    s3_log_uri: s3://REPLACE_THIS_BUCKET/logs/
    s3_scratch_uri: s3://REPLACE_THIS_BUCKET/tmp/
    export_job_name: true
    visible_to_all_users: true
    ssh_tunnel_is_open: true
    ssh_tunnel_to_job_tracker: true
  local:
    python_archives: *python_archives
